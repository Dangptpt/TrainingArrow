{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TrN9irgTwz7V"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LflH9Ow34Hxp",
        "outputId": "591123e5-5986-4d2e-8361-733068adaa26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No sentence-transformers model found with name VoVanPhuc/sup-SimCSE-VietNamese-phobert-base. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "867a88e8369e4db592ec8f4ea102882c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31f3f824251a4052be41c815760f258f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5b463ac1072459d9be3a00dc97ae9de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d91715cde72143469118431867eef68b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06cab11ba1b549f599610f56822ce01b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "695d4c5e6faa4c64ba178432809d9a32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = \"keepitreal/vietnamese-sbert\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name = 'VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxDiMbcU4Qbv",
        "outputId": "d21e6955-0cbc-4d32-e5f7-0bdc218f5e0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 10 0 (offset 0)\n",
            "Ignoring wrong pointing object 88 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "loader = PyPDFLoader('Data/Rule.pdf')\n",
        "document = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50,\n",
        "        )\n",
        "chunks = splitter.split_documents(document)\n",
        "vector_store = FAISS.from_documents(chunks, embedding=embeddings)\n",
        "vector_store.save_local(\"vectordb\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om12EX2xxENe",
        "outputId": "1a5f9d39-7cd1-40fd-fa4f-c67ba90cca22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='bắt đầu kỳ thực tập, thực tập sinh đăng ký lịch thực tập theo tháng với cán bộ phụ trách.  • Trường hợp nghỉ vào những buổi đã đăng ký thực tập cần báo trước cho cán bộ phụ trách kèm theo lý do cụ thể.  • Trường hợp thời gian thực tập không thể diễn ra theo kế hoạch đã đăng kỳ, với lý do hợp lý, thực tập sinh phải chủ động thông báo cho cán bộ phụ trách để xin phép thay đổi thời gian thực tập. • Mọi vắng mặt không lý do, hoặc không tuân thủ thời gian làm việc của công ty với lý do không hợp lý', metadata={'source': 'Data/Rule.pdf', 'page': 0}), Document(page_content='độ hòa đồng, tích cực học hỏi. • Thực tập sinh cần chủ động trong việc tìm hiểu, cố gắng nỗ lực thực hiện các vấn đề được giao. Tuân thủ Nội quy Công ty được xem như một tiêu chí để đánh giá kết quả thực tập của Thực tập sinh. Văn bản này có hiệu lực kể từ ngày ký  Hà Nội, ngày 01 tháng 05 năm 2014 Giám đốc               KOJI HOSAKA', metadata={'source': 'Data/Rule.pdf', 'page': 0}), Document(page_content='ARROW TECHNOLOGIES VIETNAM CO., LTD Room 02, Block A, 18th Floor, VTC Online Building, 18 Tam Trinh Str., Minh Khai Ward, Hai Ba Trung Dist., Hanoi Tel: 04.36331742\\t\\r \\xa0\\t\\r \\xa0NỘI QUY CÔNG TY Dành cho: Thực tập sinh 1. Quy định về thời gian thực tập • Thời gian làm việc của toàn công ty: từ 8: 30 đến 12h00 và từ 13:00 đến 17: 30 hàng ngày từ thứ Hai đến thứ Sáu.  • Thời gian thực tập tối thiểu của 1 thực tập sinh phần mềm là 20 giờ/ tuần.  • Trước khi bắt đầu kỳ thực tập, thực tập sinh đăng ký lịch', metadata={'source': 'Data/Rule.pdf', 'page': 0})]\n"
          ]
        }
      ],
      "source": [
        "vectorstore = FAISS.load_local(\"vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "question = \"Quy định về thời gian thực tập\"\n",
        "docs = vectorstore.similarity_search(question,k=3)\n",
        "print(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "dHu1Qf3759Bn",
        "outputId": "71ba02ce-9ff7-4035-f686-5a9a287979a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Thời gian làm việc của toàn công ty: từ 8: 30 đến 12h00 và từ 13:00 đến 17: 30 hàng ngày từ thứ Hai đến thứ Sáu.\n",
            "- Thời gian thực tập tối thiểu của 1 thực tập sinh phần mềm là 20 giờ/ tuần.\n"
          ]
        }
      ],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def gennerate(question):\n",
        "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "    docs = retriever.get_relevant_documents(question)\n",
        "    context = format_docs(docs)\n",
        "    prompt = f\"\"\"\n",
        "    Bạn là trợ lý cho các nhiệm vụ trả lời câu hỏi, hãy trả lời bằng tiếng Việt, lịch sự và thân thiện.\n",
        "    Hãy trả lời câu hỏi dựa trên dữ liệu có trong đoạn ngữ cảnh\n",
        "    Hãy trả lời không biết nêu không có thông tin trong đoạn ngữ cảnh\n",
        "\n",
        "    Đoạn ngữ cảnh: {context}\n",
        "\n",
        "    Câu hỏi: {question}\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text\n",
        "\n",
        "print(gennerate(\"Quy định về thời gian thực tập\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "btDXdPQZ-jHH",
        "outputId": "59dec79e-261c-4330-a6f5-e462735c8c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7863\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 532, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 832, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_5268\\2904090769.py\", line 11, in respond\n",
            "    bot_message = gennerate(message)\n",
            "                  ^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_5268\\1314198648.py\", line 18, in gennerate\n",
            "    return model.generate_content(prompt).text\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py\", line 401, in text\n",
            "    raise ValueError(\n",
            "ValueError: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(height=700)\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        bot_message = gennerate(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
