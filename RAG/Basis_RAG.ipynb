{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TrN9irgTwz7V"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LflH9Ow34Hxp",
        "outputId": "591123e5-5986-4d2e-8361-733068adaa26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "No sentence-transformers model found with name VoVanPhuc/sup-SimCSE-VietNamese-phobert-base. Creating a new one with mean pooling.\n",
            "d:\\Hust Study\\Intern\\Training\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = \"keepitreal/vietnamese-sbert\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name = 'VoVanPhuc/sup-SimCSE-VietNamese-phobert-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxDiMbcU4Qbv",
        "outputId": "d21e6955-0cbc-4d32-e5f7-0bdc218f5e0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 10 0 (offset 0)\n",
            "Ignoring wrong pointing object 88 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "loader = PyPDFLoader('Data/Rule.pdf')\n",
        "document = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500, \n",
        "        chunk_overlap=50,\n",
        "        )\n",
        "chunks = splitter.split_documents(document)\n",
        "vector_store = FAISS.from_documents(chunks, embedding=embeddings)\n",
        "vector_store.save_local(\"vectordb\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om12EX2xxENe",
        "outputId": "1a5f9d39-7cd1-40fd-fa4f-c67ba90cca22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='ARROW TECHNOLOGIES VIETNAM CO., LTD Room 02, Block A, 18th Floor, VTC Online Building, 18 Tam Trinh Str., Minh Khai Ward, Hai Ba Trung Dist., Hanoi Tel: 04.36331742\\t\\r \\xa0\\t\\r \\xa0NỘI QUY CÔNG TY Dành cho: Thực tập sinh 1. Quy định về thời gian thực tập • Thời gian làm việc của toàn công ty: từ 8: 30 đến 12h00 và từ 13:00 đến 17: 30 hàng ngày từ thứ Hai đến thứ Sáu.  • Thời gian thực tập tối thiểu của 1 thực tập sinh phần mềm là 20 giờ/ tuần.  • Trước khi bắt đầu kỳ thực tập, thực tập sinh đăng ký lịch', metadata={'source': 'Data/Rule.pdf', 'page': 0}), Document(page_content='gian làm việc của công ty với lý do không hợp lý đều sẽ ảnh hướng đến kết quả đánh giá thực tập sinh vào cuối đợt thực tập.  2. Một số quy định chung trong giờ làm việc • Ăn mặc gọn gàng, lịch sự, phù hợp môi trường văn phòng. • Không làm việc riêng trong giờ làm việc (xem phim, chat, Facebook … những nội dung không phục vụ cho công việc đang làm).. • Không download dữ liệu cá nhân (phim, ảnh, nhạc) trong và ngoài giờ làm việc. • Không chơi games trong và ngoài giờ làm việc trừ các dịp đặc biệt', metadata={'source': 'Data/Rule.pdf', 'page': 0}), Document(page_content='trong và ngoài giờ làm việc trừ các dịp đặc biệt được ban giám đốc chấp thuận. • Điện thoại để ở chế độ rung • Thân thiện với người trong công ty, tác phong nhanh nhẹn, chuyên nghiệp, tôn trọng trong công việc. • Sử dụng tiết kiệm các loại văn phòng phẩm, điện, tắt màn hình trước khi rời chỗ làm việc • Tuyệt đối bảo mật thông tin (xem rõ phụ lục đính kèm Nội quy công ty này) 3. Một số quy định riêng về thái độ làm việc • Thực tập sinh cần có thái độ hòa đồng, tích cực học hỏi. • Thực tập sinh', metadata={'source': 'Data/Rule.pdf', 'page': 0})]\n"
          ]
        }
      ],
      "source": [
        "vectorstore = FAISS.load_local(\"vectordb\", embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "question = \"nhân viên làm việc mấy giờ một ngày\"\n",
        "docs = vectorstore.similarity_search(question,k=3)\n",
        "print(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The object of the game is to complete 18 holes using the fewest strokes possible. The lower the number of strokes, the better.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        " \n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  }\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name='gemini-pro', safety_settings=safety_settings, )\n",
        "\n",
        "prompt_parts = [\n",
        "  '''\n",
        "Input: Greece is larger than mexico.\n",
        "Knowledge: Greece is approximately 131,957 sq km, while Mexico is approximately 1,964,375 sq km, making Mexico 1,389% larger than Greece.\n",
        "\n",
        "Input: Glasses always fog up.\n",
        "Knowledge: Condensation occurs on eyeglass lenses when water vapor from your sweat, breath, and ambient humidity lands on a cold surface, cools, and then changes into tiny drops of liquid, forming a film that you see as fog. Your lenses will be relatively cool compared to your breath, especially when the outside air is cold.\n",
        "\n",
        "Input: A fish is capable of thinking.\n",
        "Knowledge: Fish are more intelligent than they appear. In many areas, such as memory, their cognitive powers match or exceed those of ’higher’ vertebrates including non-human primates. Fish’s long-term memories help them keep track of complex social relationships.\n",
        "\n",
        "Input: A common effect of smoking lots of cigarettes in one’s lifetime is a higher than normal chance of getting lung cancer.\n",
        "Knowledge: Those who consistently averaged less than one cigarette per day over their lifetime had nine times the risk of dying from lung cancer than never smokers. Among people who smoked between one and 10 cigarettes per day, the risk of dying from lung cancer was nearly 12 times higher than that of never smokers.\n",
        "\n",
        "Input: A rock is the same size as a pebble.\n",
        "Knowledge: A pebble is a clast of rock with a particle size of 4 to 64 millimetres based on the Udden-Wentworth scale of sedimentology. Pebbles are generally considered larger than granules (2 to 4 millimetres diameter) and smaller than cobbles (64 to 256 millimetres diameter).\n",
        "\n",
        "Input: Part of golf is trying to get a higher point total than others.\n",
        "Knowledge:\n",
        "''', \n",
        "]\n",
        "respone = model.generate_content(prompt_parts)\n",
        "print(respone.text) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "dHu1Qf3759Bn",
        "outputId": "71ba02ce-9ff7-4035-f686-5a9a287979a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Từ 8 giờ 30 phút đến 12 giờ 00 và từ 13 giờ 00 đến 17 giờ 30\n"
          ]
        }
      ],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def gennerate(question):\n",
        "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
        "\n",
        "    docs = retriever.get_relevant_documents(question)\n",
        "    context = format_docs(docs)\n",
        "    prompt = f\"\"\"\n",
        "    Bạn là trợ lý cho các nhiệm vụ trả lời câu hỏi, hãy trả lời bằng tiếng Việt, lịch sự và thân thiện.\n",
        "    Hãy trả lời câu hỏi dựa trên dữ liệu có trong đoạn ngữ cảnh\n",
        "    Hãy trả lời không biết nêu không có thông tin trong đoạn ngữ cảnh\n",
        "\n",
        "    Đoạn ngữ cảnh: {context}\n",
        "\n",
        "    Câu hỏi: {question}\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text\n",
        "\n",
        "print(gennerate(\"Nhân viên làm việc mấy giờ một ngày\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "btDXdPQZ-jHH",
        "outputId": "59dec79e-261c-4330-a6f5-e462735c8c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7861\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "\n",
        "with gr.Blocks() as demo: \n",
        "    chatbot = gr.Chatbot(height=700)\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        bot_message = gennerate(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
